{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TKO_8966 Project report, DATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author1, Author2, …\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project report template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This template provides a suggested basic structure for project reports. You are free to choose to follow a different structure for your project reports, but please take care to include required information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please include a “contributions” section that clearly identifies who did what in your project. This information is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of sentiment annotations (mandatory)\n",
    "\n",
    "In this section, present your analysis of the provided sentiment annotations following the instructions below:\n",
    "\n",
    "After manual sentiment annotation is complete, we will merge the annotations of all students and provide every project group with a dataset summarizing the annotations in a simple tab-separated-values (TSV) format.\n",
    "\n",
    "In milestone II, project groups will *analyze this data to identify inconsistencies and challenges in annotation* as well as to *identify groups of synonymous aspects*. The data can be analysed manually, or semi-automatically by calculating and analysing basic data statistics (e.g. label frequencies, aspect frequencies etc.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic sentiment detection (mandatory)\n",
    "\n",
    "Each project group will create an automatic sentiment detection system using *the annotated data* and *a text classification method* as taught on the course (for example a bag-of-words SVM, but you are free to choose any other classification method as well).\n",
    "\n",
    "The task setting is as follows: given target texts and their right and left contexts, **assign each context to one of the sentiment classes (positive, negative, etc.).** \n",
    "\n",
    "*The sentiment detection systems will be evaluated on a held-out portion of the annotated data in terms of their accuracy.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, present your automatic sentiment detection system and the results of your evaluation. A possible structure is\n",
    "\n",
    "### Data\n",
    "\n",
    "In this subsection, present the statistics of the data that you are using to train and evaluate your system, identifying how the dataset was split into training and held-out test subsets (as well as a development subset, if any).\n",
    "\n",
    "### Method\n",
    "\n",
    "In this subsection, present the method applied to perform automatic sentiment detection, including all of its parameters and the process used to select them.\n",
    "\n",
    "### Results\n",
    "\n",
    "In this subsection, present the results of your evaluation and relate them to naive baseline results (e.g. random classification and/or always predicting the majority class)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic aspect identification (optional)\n",
    "\n",
    "Only include this subsection if you have done the bonus milestone on automatic aspect identification. In this subsection, present your automatic aspect identification system and the results of your evaluation. One possible way to organize this section is to follow the outline above (data, method, results)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-domain evaluation (optional)\n",
    "Only include this subsection if you have done the bonus milestone on out-of-domain evaluation. In this section, present the data prepared for out-of-domain evaluation as well as the results of the evaluation of your method on this data. One possible way to organize this section is to follow the outline above (data, method, results).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
